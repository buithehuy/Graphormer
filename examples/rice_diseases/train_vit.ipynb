{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer (ViT) — Rice Diseases Classification\n",
    "\n",
    "**Mục tiêu**: So sánh **công bằng** giữa ViT và Graphormer trên cùng một bộ dữ liệu bệnh lúa.  \n",
    "Pipeline dataset (split, augmentation, seed) **giống hệt** `train_graphormer_simple.py`.\n",
    "\n",
    "---\n",
    "### Điều kiện so sánh công bằng đã đảm bảo\n",
    "| Yếu tố | Graphormer | ViT (notebook này) |\n",
    "|---|---|---|\n",
    "| Splits | 70/15/15 stratified, seed=42 | **Giống hệt** (dùng cùng file `split_indices.pt`) |\n",
    "| Augmentation | rotate90/180/270, flipH/V, zoom in/out | **Giống hệt** (áp dụng torchvision tương đương) |\n",
    "| Optimizer | AdamW, lr=3e-4, wd=0.01 | **Giống hệt** |\n",
    "| Scheduler | Polynomial decay + 1000 warmup | **Giống hệt** |\n",
    "| Mixed precision | FP16 (`--fp16`) | AMP FP16 |\n",
    "| Gradient clipping | 5.0 | **Giống hệt** |\n",
    "| Seed | 42 | **Giống hệt** |\n",
    "| Classes | 4 (BrownSpot/Healthy/Hispa/LeafBlast) | **Giống hệt** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cài đặt thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chạy cell này một lần duy nhất trên Colab\n",
    "!pip install timm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Siêu tham số (tùy chỉnh tại đây)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "#  CẤU HÌNH — Chỉnh các giá trị ở đây trước khi chạy\n",
    "# ==========================================================================\n",
    "\n",
    "# ── Đường dẫn dữ liệu ──────────────────────────────────────────────────────\n",
    "# Trỏ đến thư mục chứa ảnh gốc (cùng cấu trúc mà process_images.py đọc).\n",
    "# Ví dụ Colab: '/content/drive/MyDrive/rice_diseases_data'\n",
    "IMAGE_DIR = '/content/rice_diseases_data'   # ← thay đổi nếu cần\n",
    "\n",
    "# Thư mục chứa split_indices.pt và metadata.json đã được Graphormer tạo sẵn.\n",
    "# Nếu không có (chưa từng chạy process_images.py), để None → tự tạo split mới.\n",
    "GRAPHORMER_PROCESSED_DIR = '/content/Graphormer/examples/rice_diseases/rice_diseases_graphs/processed'\n",
    "\n",
    "# ── Mô hình ViT ────────────────────────────────────────────────────────────\n",
    "# 'vit_small_patch16_224'  → ~22M params  ← đề xuất cho Colab T4\n",
    "# 'vit_tiny_patch16_224'   → ~5.7M params ← nhẹ hơn nếu RAM hạn chế\n",
    "# 'vit_base_patch16_224'   → ~86M params  ← mạnh hơn, cần nhiều VRAM hơn\n",
    "VIT_MODEL_NAME = 'vit_small_patch16_224'   # ← thay đổi nếu muốn\n",
    "\n",
    "# Pretrained trên ImageNet?\n",
    "# True  = fine-tune (thường tốt hơn, nhưng có thể không \"công bằng\" nếu Graphormer train từ đầu)\n",
    "# False = train from scratch (công bằng nhất với Graphormer không dùng pretrained)\n",
    "USE_PRETRAINED = False                     # ← thay đổi theo mục tiêu paper\n",
    "\n",
    "# ── Training ───────────────────────────────────────────────────────────────\n",
    "EPOCHS      = 50          # Graphormer simple: 50 epochs\n",
    "BATCH_SIZE  = 32          # Graphormer simple: 32\n",
    "LR          = 3e-4        # === Graphormer: 3e-4\n",
    "WEIGHT_DECAY= 1e-2        # === Graphormer: 0.01\n",
    "CLIP_NORM   = 5.0         # === Graphormer: --clip-norm 5.0\n",
    "WARMUP_STEPS= 1000        # === Graphormer: --warmup-updates 1000\n",
    "NUM_WORKERS = 2           # Số worker cho DataLoader\n",
    "SEED        = 42          # === Graphormer seed\n",
    "\n",
    "# ── Ảnh đầu vào ────────────────────────────────────────────────────────────\n",
    "IMG_SIZE    = 224         # ViT patch16 cần 224×224\n",
    "\n",
    "# ── Lưu checkpoint ─────────────────────────────────────────────────────────\n",
    "SAVE_DIR    = './ckpts_vit_rice'\n",
    "\n",
    "# ── Augmentation (giống process_images.py của Graphormer) ────────────────\n",
    "USE_AUGMENTATION = True   # Bật augmentation như Graphormer\n",
    "\n",
    "# ── Mixed Precision ────────────────────────────────────────────────────────\n",
    "USE_AMP     = True        # === Graphormer: --fp16\n",
    "\n",
    "# ==========================================================================\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"  Model         : {VIT_MODEL_NAME}\")\n",
    "print(f\"  Pretrained    : {USE_PRETRAINED}\")\n",
    "print(f\"  Epochs        : {EPOCHS}\")\n",
    "print(f\"  Batch size    : {BATCH_SIZE}\")\n",
    "print(f\"  LR            : {LR}\")\n",
    "print(f\"  Weight decay  : {WEIGHT_DECAY}\")\n",
    "print(f\"  AMP (FP16)    : {USE_AMP}\")\n",
    "print(f\"  Augmentation  : {USE_AUGMENTATION}\")\n",
    "print(f\"  Seed          : {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports & Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Fix all random seeds for full reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device : {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU    : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM   : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset — Cùng split và augmentation với Graphormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.1  Tìm ảnh và đọc split indices (giống hệt Graphormer)\n",
    "# ============================================================\n",
    "\n",
    "CLASS_NAMES = ['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n",
    "CLASS_TO_IDX = {n: i for i, n in enumerate(CLASS_NAMES)}\n",
    "\n",
    "\n",
    "def find_images(image_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Tìm ảnh theo đúng cấu trúc thư mục của process_images.py.\n",
    "    Hỗ trợ cả2 cấu trúc: LabelledRice/Labelled và RiceDiseaseDataset/.\n",
    "    \"\"\"\n",
    "    data_dict = {c: [] for c in CLASS_NAMES}\n",
    "    base = Path(image_dir)\n",
    "\n",
    "    labelled_dir = base / 'LabelledRice' / 'Labelled'\n",
    "    if not labelled_dir.exists():\n",
    "        labelled_dir = base / 'Labelled'\n",
    "\n",
    "    if labelled_dir.exists():\n",
    "        for cls in CLASS_NAMES:\n",
    "            cls_dir = labelled_dir / cls\n",
    "            if cls_dir.exists():\n",
    "                imgs = (list(cls_dir.glob('*.jpg')) +\n",
    "                        list(cls_dir.glob('*.jpeg')) +\n",
    "                        list(cls_dir.glob('*.png')))\n",
    "                data_dict[cls] = [str(p) for p in imgs]\n",
    "    else:\n",
    "        for split_name in ['train', 'validation']:\n",
    "            split_dir = base / 'RiceDiseaseDataset' / split_name\n",
    "            if split_dir.exists():\n",
    "                for cls in CLASS_NAMES:\n",
    "                    cls_dir = split_dir / cls\n",
    "                    if cls_dir.exists():\n",
    "                        imgs = (list(cls_dir.glob('*.jpg')) +\n",
    "                                list(cls_dir.glob('*.jpeg')) +\n",
    "                                list(cls_dir.glob('*.png')))\n",
    "                        data_dict[cls].extend([str(p) for p in imgs])\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "# Tìm ảnh\n",
    "data_dict = find_images(IMAGE_DIR)\n",
    "\n",
    "# Tạo danh sách phẳng (path, label)\n",
    "all_paths, all_labels = [], []\n",
    "for cls in CLASS_NAMES:\n",
    "    for p in data_dict[cls]:\n",
    "        all_paths.append(p)\n",
    "        all_labels.append(CLASS_TO_IDX[cls])\n",
    "\n",
    "# Sắp xếp để đảm bảo thứ tự ổn định\n",
    "all_paths  = np.array(all_paths)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"Total images found: {len(all_paths)}\")\n",
    "for cls in CLASS_NAMES:\n",
    "    n = (all_labels == CLASS_TO_IDX[cls]).sum()\n",
    "    print(f\"  {cls:12s}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.2  Tạo split — ưu tiên đọc file split_indices.pt của Graphormer\n",
    "#       để đảm bảo CÙNG TẬP TRAIN/VAL/TEST\n",
    "# ============================================================\n",
    "\n",
    "split_file = Path(GRAPHORMER_PROCESSED_DIR) / 'split_indices.pt' if GRAPHORMER_PROCESSED_DIR else None\n",
    "\n",
    "def create_stratified_splits(n, labels, seed=42):\n",
    "    \"\"\"Tạo split 70/15/15 stratified — giống hệt rice_diseases_dataset.py.\"\"\"\n",
    "    indices = np.arange(n)\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        indices, test_size=0.3, stratify=labels, random_state=seed\n",
    "    )\n",
    "    temp_labels = labels[temp_idx]\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx, test_size=0.5, stratify=temp_labels, random_state=seed\n",
    "    )\n",
    "    return (\n",
    "        torch.from_numpy(train_idx),\n",
    "        torch.from_numpy(val_idx),\n",
    "        torch.from_numpy(test_idx)\n",
    "    )\n",
    "\n",
    "\n",
    "if split_file and split_file.exists():\n",
    "    # ── TRƯỜNG HỢP 1: Dùng split sẵn có của Graphormer ──────────────────\n",
    "    # Lưu ý: split_indices.pt của Graphormer được tạo trên danh sách ảnh\n",
    "    # được xử lý theo thứ tự CLASS_NAMES -> file index trong process_images.py.\n",
    "    # Để mapping chính xác, ta cần đọc metadata.json để biết order.\n",
    "    print(f\"Found Graphormer split file: {split_file}\")\n",
    "\n",
    "    meta_file = Path(GRAPHORMER_PROCESSED_DIR) / 'metadata.json'\n",
    "    if meta_file.exists():\n",
    "        with open(meta_file) as f:\n",
    "            meta = json.load(f)\n",
    "        # image_paths trong metadata đúng thứ tự tạo .pt files\n",
    "        graphormer_paths = np.array(meta['image_paths'])\n",
    "        graphormer_labels = np.array(meta['labels'])\n",
    "\n",
    "        splits = torch.load(split_file)\n",
    "        train_idx = splits['train_idx']\n",
    "        val_idx   = splits['val_idx']\n",
    "        test_idx  = splits['test_idx']\n",
    "\n",
    "        # Mapping từ Graphormer indices → ViT dataset\n",
    "        # ViT dùng graphormer_paths/labels trực tiếp\n",
    "        vit_paths  = graphormer_paths\n",
    "        vit_labels = graphormer_labels\n",
    "        print(\"  ✓ Using Graphormer's exact image ordering and splits (strongest guarantee).\")\n",
    "\n",
    "    else:\n",
    "        print(\"  WARNING: metadata.json not found. Cannot map Graphormer splits to image paths.\")\n",
    "        print(\"  Falling back to fresh stratified split (same algorithm, may differ in exact samples).\")\n",
    "        vit_paths, vit_labels = all_paths, all_labels\n",
    "        train_idx, val_idx, test_idx = create_stratified_splits(len(vit_paths), vit_labels, SEED)\n",
    "\n",
    "else:\n",
    "    # ── TRƯỜNG HỢP 2: Tạo split mới với cùng thuật toán ─────────────────\n",
    "    print(\"No Graphormer split file found. Creating fresh 70/15/15 stratified split.\")\n",
    "    print(\"Algorithm is identical to rice_diseases_dataset.py.\")\n",
    "    vit_paths, vit_labels = all_paths, all_labels\n",
    "    train_idx, val_idx, test_idx = create_stratified_splits(len(vit_paths), vit_labels, SEED)\n",
    "\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train : {len(train_idx)}\")\n",
    "print(f\"  Val   : {len(val_idx)}\")\n",
    "print(f\"  Test  : {len(test_idx)}\")\n",
    "\n",
    "# Per-class distribution in train set\n",
    "train_labels_arr = vit_labels[train_idx.numpy()]\n",
    "print(\"\\nTrain class distribution:\")\n",
    "for cls in CLASS_NAMES:\n",
    "    n = (train_labels_arr == CLASS_TO_IDX[cls]).sum()\n",
    "    print(f\"  {cls:12s}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.3  Transforms — Augmentation giống hệt process_images.py\n",
    "# ============================================================\n",
    "\n",
    "# Graphormer augmentations: rotate_90, rotate_180, rotate_270,\n",
    "#   flip_horizontal, flip_vertical, zoom_in (crop 80%), zoom_out (pad)\n",
    "# → tương đương với torchvision RandomApply / RandomRotation\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]   # ImageNet stats\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "def build_train_transform(img_size: int, augment: bool) -> T.Compose:\n",
    "    ops = [T.Resize((img_size, img_size))]\n",
    "\n",
    "    if augment:\n",
    "        ops += [\n",
    "            # Rotate 0/90/180/270\n",
    "            T.RandomApply([T.RandomRotation(degrees=(90, 90))],  p=0.33),\n",
    "            T.RandomApply([T.RandomRotation(degrees=(180, 180))], p=0.33),\n",
    "            T.RandomApply([T.RandomRotation(degrees=(270, 270))], p=0.33),\n",
    "            # Flip H / V\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            # Zoom-in: random crop (80% of area) → resize back (≈ zoom-in)\n",
    "            T.RandomApply([T.RandomResizedCrop(img_size, scale=(0.64, 0.80))], p=0.5),\n",
    "            # Color jitter (optional — Graphormer doesn't use, so disabled by default)\n",
    "            # T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        ]\n",
    "\n",
    "    ops += [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    "    return T.Compose(ops)\n",
    "\n",
    "\n",
    "def build_eval_transform(img_size: int) -> T.Compose:\n",
    "    return T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ])\n",
    "\n",
    "\n",
    "train_transform = build_train_transform(IMG_SIZE, USE_AUGMENTATION)\n",
    "eval_transform  = build_eval_transform(IMG_SIZE)\n",
    "\n",
    "print(\"Train transform:\")\n",
    "print(train_transform)\n",
    "print(\"\\nEval transform:\")\n",
    "print(eval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.4  Dataset class\n",
    "# ============================================================\n",
    "\n",
    "class RiceDiseaseImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads raw images from disk and applies torchvision transforms.\n",
    "    Uses the same train/val/test indices as the Graphormer pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, paths: np.ndarray, labels: np.ndarray, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = int(self.labels[idx])\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# Build full dataset with train transform (will slice per-split)\n",
    "train_dataset = RiceDiseaseImageDataset(\n",
    "    vit_paths[train_idx.numpy()], vit_labels[train_idx.numpy()], transform=train_transform\n",
    ")\n",
    "val_dataset = RiceDiseaseImageDataset(\n",
    "    vit_paths[val_idx.numpy()], vit_labels[val_idx.numpy()], transform=eval_transform\n",
    ")\n",
    "test_dataset = RiceDiseaseImageDataset(\n",
    "    vit_paths[test_idx.numpy()], vit_labels[test_idx.numpy()], transform=eval_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True, drop_last=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)} | Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model — ViT via `timm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Tại sao chọn vit_small_patch16_224?\n",
    "# ============================================================\n",
    "#\n",
    "#  Graphormer slim (fairseq): 12 layers, embed=256, ffn=512, heads=8\n",
    "#   → ước tính ~6–10M param\n",
    "#\n",
    "#  ViT-Small patch16:  12 layers, embed=384, heads=6  → ~22M params (pretrain=False)\n",
    "#  ViT-Tiny  patch16:  12 layers, embed=192, heads=3  →  ~5.7M params\n",
    "#\n",
    "#  Đề xuất:\n",
    "#  • USE_PRETRAINED=False, VIT_MODEL_NAME='vit_small_patch16_224'\n",
    "#    → công bằng nhất (cùng kiến trúc từ scratch)\n",
    "#  • Nếu muốn thể hiện sức mạnh transfer learning:\n",
    "#    USE_PRETRAINED=True và ghi rõ trong paper\n",
    "\n",
    "model = timm.create_model(\n",
    "    VIT_MODEL_NAME,\n",
    "    pretrained=USE_PRETRAINED,\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model      : {VIT_MODEL_NAME}\")\n",
    "print(f\"Pretrained : {USE_PRETRAINED}\")\n",
    "print(f\"Parameters : {n_params:,}\")\n",
    "print(f\"Num classes: {len(CLASS_NAMES)}: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer & Scheduler — Giống hệt Graphormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW — giống Graphormer: adam-betas=(0.9,0.999), adam-eps=1e-8\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Polynomial decay with linear warmup\n",
    "# Graphormer: --lr-scheduler polynomial_decay --power 1\n",
    "#             --warmup-updates 1000 --total-num-update 50000\n",
    "total_steps  = EPOCHS * len(train_loader)\n",
    "warmup_steps = min(WARMUP_STEPS, total_steps // 10)\n",
    "\n",
    "\n",
    "def lr_lambda(current_step: int):\n",
    "    \"\"\"Linear warmup then polynomial (linear) decay — mirrors Graphormer.\"\"\"\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / float(max(1, warmup_steps))\n",
    "    progress = (current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "    return max(0.0, 1.0 - progress)   # power=1 → linear decay\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# AMP scaler\n",
    "scaler = GradScaler(enabled=USE_AMP)\n",
    "\n",
    "print(f\"Optimizer    : AdamW(lr={LR}, wd={WEIGHT_DECAY}, betas=(0.9, 0.999))\")\n",
    "print(f\"Scheduler    : Polynomial decay (linear), warmup={warmup_steps} steps\")\n",
    "print(f\"Total steps  : {total_steps}\")\n",
    "print(f\"AMP enabled  : {USE_AMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = total_correct = total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=USE_AMP):\n",
    "            logits = model(imgs)                      # (B, num_classes)\n",
    "            loss   = F.cross_entropy(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        # Gradient clipping — giống Graphormer: --clip-norm 5.0\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        total_loss    += loss.item() * labels.size(0)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total         += labels.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = total_correct = total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with autocast(enabled=USE_AMP):\n",
    "            logits = model(imgs)\n",
    "            loss   = F.cross_entropy(logits, labels)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        total_loss    += loss.item() * labels.size(0)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total         += labels.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "print(\"Training functions ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "header = f\"{'Epoch':>6} {'TrainLoss':>10} {'TrainAcc':>9} {'ValLoss':>9} {'ValAcc':>8} {'LR':>10} {'Time':>7}\"\n",
    "sep    = '─' * 66\n",
    "print(sep)\n",
    "print(header)\n",
    "print(sep)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, DEVICE)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, DEVICE)\n",
    "\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # Log\n",
    "    history['train_loss'].append(tr_loss)\n",
    "    history['train_acc'].append(tr_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "\n",
    "    print(f\"{epoch:6d}  {tr_loss:10.4f}  {tr_acc*100:8.2f}%  {val_loss:9.4f}  {val_acc*100:7.2f}%  \"\n",
    "          f\"{current_lr:.2e}  {elapsed:5.1f}s\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        ckpt = {\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'config': {\n",
    "                'model_name': VIT_MODEL_NAME,\n",
    "                'pretrained': USE_PRETRAINED,\n",
    "                'seed': SEED,\n",
    "                'epochs': EPOCHS,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'lr': LR,\n",
    "                'weight_decay': WEIGHT_DECAY,\n",
    "                'augmentation': USE_AUGMENTATION,\n",
    "                'amp': USE_AMP,\n",
    "            }\n",
    "        }\n",
    "        torch.save(ckpt, os.path.join(SAVE_DIR, 'best_model.pt'))\n",
    "        print(f\"         ✓ Best checkpoint saved (val_acc={val_acc*100:.2f}%)\")\n",
    "\n",
    "print(sep)\n",
    "print(f\"Training complete. Best val acc: {best_val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_path = os.path.join(SAVE_DIR, 'best_model.pt')\n",
    "if os.path.exists(best_path):\n",
    "    ckpt = torch.load(best_path, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['model_state'])\n",
    "    print(f\"Loaded best model from epoch {ckpt['epoch']} (val_acc={ckpt['val_acc']*100:.2f}%)\")\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, DEVICE)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  FINAL TEST RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Test Loss    : {test_loss:.4f}\")\n",
    "print(f\"  Test Acc     : {test_acc*100:.2f}%\")\n",
    "print(f\"  Best Val Acc : {best_val_acc*100:.2f}%\")\n",
    "\n",
    "# Per-class accuracy & confusion\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        with autocast(enabled=USE_AMP):\n",
    "            logits = model(imgs)\n",
    "        preds = logits.argmax(dim=-1).cpu()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_targets.extend(labels.tolist())\n",
    "\n",
    "all_preds   = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "print(f\"\\n  Per-class accuracy:\")\n",
    "print(f\"  {'Class':15s}  {'Correct':>7}  {'Total':>7}  {'Acc':>8}\")\n",
    "print(f\"  {'-'*42}\")\n",
    "for c, cls_name in enumerate(CLASS_NAMES):\n",
    "    mask = all_targets == c\n",
    "    correct = (all_preds[mask] == c).sum()\n",
    "    total_c = mask.sum()\n",
    "    acc_c   = correct / total_c * 100 if total_c > 0 else 0.0\n",
    "    print(f\"  {cls_name:15s}  {correct:7d}  {total_c:7d}  {acc_c:7.2f}%\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title(f'ViT Confusion Matrix — Test Set\\n({VIT_MODEL_NAME}, pretrained={USE_PRETRAINED})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=CLASS_NAMES, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs_range, history['train_loss'], label='Train', color='steelblue')\n",
    "axes[0].plot(epochs_range, history['val_loss'],   label='Val',   color='orangered')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Cross-Entropy Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs_range, [a*100 for a in history['train_acc']], label='Train', color='steelblue')\n",
    "axes[1].plot(epochs_range, [a*100 for a in history['val_acc']],   label='Val',   color='orangered')\n",
    "axes[1].axhline(y=best_val_acc*100, color='green', linestyle='--', alpha=0.7, label=f'Best Val={best_val_acc*100:.1f}%')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[2].plot(epochs_range, history['lr'], color='purple')\n",
    "axes[2].set_title('Learning Rate (per epoch)')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('LR')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'ViT Training — {VIT_MODEL_NAME} | pretrained={USE_PRETRAINED} | aug={USE_AUGMENTATION}', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'learning_curves.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary — Thông tin cho Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  EXPERIMENT SUMMARY (for paper)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Model             : {VIT_MODEL_NAME}\")\n",
    "print(f\"  Pretrained        : {USE_PRETRAINED}\")\n",
    "print(f\"  Parameters        : {n_params:,}\")\n",
    "print(f\"  Image size        : {IMG_SIZE}×{IMG_SIZE}\")\n",
    "print(f\"  Batch size        : {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate     : {LR}\")\n",
    "print(f\"  Weight decay      : {WEIGHT_DECAY}\")\n",
    "print(f\"  LR schedule       : Linear warmup ({warmup_steps} steps) + Polynomial decay\")\n",
    "print(f\"  Clip norm         : {CLIP_NORM}\")\n",
    "print(f\"  Mixed precision   : {USE_AMP}\")\n",
    "print(f\"  Augmentation      : {USE_AUGMENTATION}\")\n",
    "print(f\"  Epochs            : {EPOCHS}\")\n",
    "print(f\"  Seed              : {SEED}\")\n",
    "print(f\"  Dataset split     : 70/15/15 stratified\")\n",
    "print(f\"  Train / Val / Test: {len(train_dataset)} / {len(val_dataset)} / {len(test_dataset)}\")\n",
    "print(f\"  Classes           : {CLASS_NAMES}\")\n",
    "print(\"─\" * 60)\n",
    "print(f\"  Best Val Acc      : {best_val_acc*100:.2f}%\")\n",
    "print(f\"  Test Acc          : {test_acc*100:.2f}%\")\n",
    "print(f\"  Test Loss         : {test_loss:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
